{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"input/spamorham.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20348, 2)\n",
      "(20348, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \"text\" column contains the message text and \"text_type\" contains the labels (spam or not)\n",
    "X = df['text']\n",
    "y = df['text_type']\n",
    "\n",
    "# Convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to make them uniform length\n",
    "max_sequence_length = 100  # Choose the maximum length of sequences\n",
    "X_train_pad = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\__Projects__\\Deep-Learning-Experiments\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.7399 - loss: 0.5066 - val_accuracy: 0.9081 - val_loss: 0.2115\n",
      "Epoch 2/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9468 - loss: 0.1582 - val_accuracy: 0.9437 - val_loss: 0.1397\n",
      "Epoch 3/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9695 - loss: 0.0930 - val_accuracy: 0.9619 - val_loss: 0.1155\n",
      "Epoch 4/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9790 - loss: 0.0660 - val_accuracy: 0.9526 - val_loss: 0.1345\n",
      "Epoch 5/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9833 - loss: 0.0503 - val_accuracy: 0.9376 - val_loss: 0.1883\n",
      "Epoch 6/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9861 - loss: 0.0462 - val_accuracy: 0.9523 - val_loss: 0.1472\n",
      "Epoch 7/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9879 - loss: 0.0362 - val_accuracy: 0.9496 - val_loss: 0.1572\n",
      "Epoch 8/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9872 - loss: 0.0388 - val_accuracy: 0.9533 - val_loss: 0.1514\n",
      "Epoch 9/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9880 - loss: 0.0350 - val_accuracy: 0.9553 - val_loss: 0.1537\n",
      "Epoch 10/10\n",
      "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9925 - loss: 0.0218 - val_accuracy: 0.9582 - val_loss: 0.1568\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=64, input_length=max_sequence_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_data=(X_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "model.save(\"output/spam_or_ham_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "w:\\__Projects__\\Deep-Learning-Experiments\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 7 variables whereas the saved optimizer has 12 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "#Load the model\n",
    "model = tf.keras.models.load_model(\"output/spam_or_ham_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model is done on the test set, which is not available to us. Therefore, we will split the training data into training and validation sets. We will use the validation set to tune the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9625 - loss: 0.1387\n",
      "Test Loss: 0.15683908760547638\n",
      "Test Accuracy: 0.9582309722900391\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step\n",
      "Confusion Matrix:\n",
      "[[2856   57]\n",
      " [ 113 1044]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      2913\n",
      "           1       0.95      0.90      0.92      1157\n",
      "\n",
      "    accuracy                           0.96      4070\n",
      "   macro avg       0.96      0.94      0.95      4070\n",
      "weighted avg       0.96      0.96      0.96      4070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Further evaluation metrics\n",
    "y_pred = model.predict(X_test_pad)\n",
    "y_pred = (y_pred > 0.5) # Convert the probabilities to binary predictions\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "##classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate with user defined test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text=\"Congratulations! You have been selected as a winner. Text WON to 44255 to claim your prize.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "The text message is spam.\n",
      "At accuracy:  0.954054057598114\n",
      "The model is  90.2423620223999 % sure that the text message is spam.\n"
     ]
    }
   ],
   "source": [
    "# Example of classifying a new text_message\n",
    "#new_text_message = [\"Your new text_message text goes here\"]\n",
    "new_text_message = [my_text]\n",
    "new_text_message_seq = tokenizer.texts_to_sequences(new_text_message)\n",
    "new_text_message_pad = pad_sequences(new_text_message_seq, maxlen=max_sequence_length)\n",
    "prediction = model.predict(new_text_message_pad)\n",
    "\n",
    "#Print the prediction (0 = ham, 1 = spam) and print the accuracy of the model\n",
    "if prediction[0][0] >= 0.5:\n",
    "    print(\"The text message is spam.\")\n",
    "    #print accuracy of the model\n",
    "    print(\"At accuracy: \", accuracy)\n",
    "    #print how sure it is that the text message is spam\n",
    "    print(\"The model is \", prediction[0][0]*100, \"% sure that the text message is spam.\")\n",
    "    \n",
    "else:\n",
    "    print(\"The text message is ham.\")\n",
    "    #print accuracy of the model\n",
    "    print(\"At accuracy: \", accuracy)\n",
    "    #print how sure it is that the text message is ham\n",
    "    print(\"The model is \", (1-prediction[0][0])*100, \"% sure that the text message is not spam (ham).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
